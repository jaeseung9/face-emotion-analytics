import streamlit as st
import cv2
import numpy as np

from face_detector import FaceDetector
from emotion_classifier import EmotionClassifier
from analytics_manager import AnalyticsManager
from utils import open_camera, resize_frame, crop_face

st.set_page_config(page_title="Real-time Emotion Analytics", layout="wide")
st.title("ğŸ˜Š Real-time Face Emotion Analytics Dashboard")

st.write("ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")


face_detector = FaceDetector("resources/haarcascade_frontalface_default.xml")
emotion_classifier = EmotionClassifier("models/emotion-ferplus.onnx")
analytics = AnalyticsManager()

st.success("ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ!")



st.subheader("ğŸ“· í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê°ì • ë¶„ì„")

uploaded = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])

if uploaded:
    file_bytes = np.asarray(bytearray(uploaded.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

    # ì–¼êµ´ ê²€ì¶œ
    faces = face_detector.detect(img)

    if len(faces) == 0:
        st.warning("ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for (x, y, w, h) in faces:
            roi = crop_face(img, x, y, w, h)
            label, conf = emotion_classifier.predict(roi)
            analytics.update(label, conf)

            # í™”ë©´ì— ê·¸ë¦¬ê¸°ìš©
            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(img, f"{label} ({conf:.2f})", (x, y-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)

        st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), caption="ë¶„ì„ ê²°ê³¼")



st.subheader("ğŸ“Š ìµœê·¼ ê°ì • ê¸°ë¡ (DEBUG ì¶œë ¥)")

df = analytics.get_recent_df()
st.dataframe(df)
